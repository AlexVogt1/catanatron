{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gymnasium as gym\n",
    "from pprint import pprint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gym' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcatanatron_gym:catanatron-v1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m observation, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m      3\u001b[0m pprint(\u001b[38;5;28mvars\u001b[39m(env))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gym' is not defined"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"catanatron_gym:catanatron-v1\")\n",
    "observation, info = env.reset()\n",
    "pprint(vars(env))\n",
    "print(observation)\n",
    "for _ in range(1000):\n",
    "    # your agent here (this takes random actions)\n",
    "    action = random.choice(env.unwrapped.get_valid_actions())\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    if done:\n",
    "        pprint(vars(env))\n",
    "        print(env.game.state)\n",
    "        observation, info = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614,)\n",
      "{'valid_actions': [289]}\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(observation.shape)\n",
    "print(info)\n",
    "print(truncated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_action_space': None,\n",
      " '_cached_spec': None,\n",
      " '_metadata': None,\n",
      " '_observation_space': None,\n",
      " '_reward_range': None,\n",
      " '_saved_kwargs': {},\n",
      " 'checked_render': False,\n",
      " 'checked_reset': True,\n",
      " 'checked_step': False,\n",
      " 'close_called': False,\n",
      " 'env': <catanatron_gym.envs.catanatron_env.CatanatronEnv object at 0x7fa9554e9190>}\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "-1\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "-1\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "-1\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "-1\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "-1\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "-1\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "-1\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "-1\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "-1\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "[RandomPlayer:RED]\n",
      "WeightedRandomPlayer:WHITE\n"
     ]
    }
   ],
   "source": [
    "from catanatron import Color\n",
    "from catanatron.players.weighted_random import WeightedRandomPlayer\n",
    "from catanatron.players.search import VictoryPointPlayer\n",
    "from catanatron_gym.envs.catanatron_env import from_action_space\n",
    "\n",
    "def my_reward_function(game, p0_color):\n",
    "    winning_color = game.winning_color()\n",
    "    if p0_color == winning_color:\n",
    "        return 100\n",
    "    elif winning_color is None:\n",
    "        return 0\n",
    "    else:\n",
    "        return -100\n",
    "\n",
    "# 3-player catan on a \"Mini\" map (7 tiles) until 6 points.\n",
    "env = gym.make(\n",
    "    \"catanatron_gym:catanatron-v1\",\n",
    "    config={\n",
    "        \"map_type\": \"BASE\",\n",
    "        \"vps_to_win\": 6,\n",
    "        # \"enemies\": [Pla(Color.RED)],\n",
    "        # \"reward_function\": my_reward_function,\n",
    "        \"representation\": \"vector\",\n",
    "    },\n",
    ")                                                       \n",
    "observation, info = env.reset()\n",
    "# pprint(vars(env))\n",
    "# print(observation.shape)\n",
    "# env.p0 = VictoryPointPlayer(Color.BLUE)\n",
    "pprint(vars(env.env))\n",
    "agent = WeightedRandomPlayer(Color.WHITE)\n",
    "env.p0 = agent\n",
    "for _ in range(1000):\n",
    "    # your agent here (this takes random actions)\n",
    "    # valid_actions = env.unwrapped.get_valid_actions()# list[int]\n",
    "    # print(len(valid_actions))\n",
    "    # print(len(env.unwrapped.get_playable_actions()))\n",
    "    # print(len(env.game.state.playable_actions))\n",
    "    # print(from_action_space(94,env.game.state.playable_actions ))\n",
    "    #convert valid actions to playable actions for agent\n",
    "    # playable_actions = \n",
    "    # action = random.choice(env.unwrapped.get_valid_actions())\n",
    "    # print(list(map(env.to_action_space, env.game.state.playable_actions)))\n",
    "    # print(env.get_valid_actions())\n",
    "    action =agent.decide(game = env.game, playable_actions=env.game.state.playable_actions)\n",
    "    # print(action)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    # print(reward)\n",
    "    # print(info)\n",
    "    done = terminated or truncated\n",
    "    if done:\n",
    "        # pprint(vars(env))\n",
    "        # print(env.game.state)\n",
    "        # print(observation)\n",
    "        print(reward)\n",
    "        observation, info = env.reset()\n",
    "print(env.enemies)\n",
    "print(env.p0)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color.ORANGE\n"
     ]
    }
   ],
   "source": [
    "from catanatron import Game, RandomPlayer, Color\n",
    "from catanatron.players.weighted_random import WeightedRandomPlayer\n",
    "from catanatron.players.search import VictoryPointPlayer\n",
    "\n",
    "# Play a simple 4v4 game\n",
    "players = [\n",
    "    RandomPlayer(Color.RED),\n",
    "    WeightedRandomPlayer(Color.BLUE),\n",
    "    RandomPlayer(Color.WHITE),\n",
    "    RandomPlayer(Color.ORANGE),\n",
    "]\n",
    "game = Game(players)\n",
    "print(game.play()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/catanatron/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.action_masks to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.action_masks` for environment variables or `env.get_wrapper_attr('action_masks')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/alex/anaconda3/envs/catanatron/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_valid_actions to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_valid_actions` for environment variables or `env.get_wrapper_attr('get_valid_actions')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 364      |\n",
      "|    ep_rew_mean     | -20      |\n",
      "| time/              |          |\n",
      "|    fps             | 555      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 483          |\n",
      "|    ep_rew_mean          | -25          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 494          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030232132 |\n",
      "|    clip_fraction        | 0.0314       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.468       |\n",
      "|    explained_variance   | 0.00386      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 40.5         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00929     |\n",
      "|    value_loss           | 174          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 528          |\n",
      "|    ep_rew_mean          | 9.09         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 482          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022864775 |\n",
      "|    clip_fraction        | 0.0318       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.46        |\n",
      "|    explained_variance   | 0.139        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 43.4         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    value_loss           | 91.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 478          |\n",
      "|    ep_rew_mean          | -25          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 477          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035674416 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.485       |\n",
      "|    explained_variance   | 0.147        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.4          |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00954     |\n",
      "|    value_loss           | 82.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 499          |\n",
      "|    ep_rew_mean          | -20          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 473          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033516646 |\n",
      "|    clip_fraction        | 0.0408       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.412       |\n",
      "|    explained_variance   | 0.0823       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 71.3         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.007       |\n",
      "|    value_loss           | 123          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 513        |\n",
      "|    ep_rew_mean          | -13        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 471        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 26         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00172874 |\n",
      "|    clip_fraction        | 0.0184     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.37      |\n",
      "|    explained_variance   | 0.236      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.95       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.00573   |\n",
      "|    value_loss           | 89.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 516         |\n",
      "|    ep_rew_mean          | 3.7         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 469         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002293783 |\n",
      "|    clip_fraction        | 0.0233      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.437      |\n",
      "|    explained_variance   | -0.167      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.3        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00663    |\n",
      "|    value_loss           | 62.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 539         |\n",
      "|    ep_rew_mean          | 6.67        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 468         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005373626 |\n",
      "|    clip_fraction        | 0.0509      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.525      |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 73.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 522          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 468          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026846472 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.407       |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 32.3         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00504     |\n",
      "|    value_loss           | 50.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 502          |\n",
      "|    ep_rew_mean          | -5           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 467          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030648033 |\n",
      "|    clip_fraction        | 0.041        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.449       |\n",
      "|    explained_variance   | 0.044        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00838     |\n",
      "|    value_loss           | 62.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 523          |\n",
      "|    ep_rew_mean          | -2.33        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 467          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043953615 |\n",
      "|    clip_fraction        | 0.0479       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.43         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 49.1         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00807     |\n",
      "|    value_loss           | 71           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 499          |\n",
      "|    ep_rew_mean          | -2.04        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 466          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032741295 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00863     |\n",
      "|    value_loss           | 44.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 488          |\n",
      "|    ep_rew_mean          | 3.7          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018293229 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.132        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 29.3         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    value_loss           | 72.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 492          |\n",
      "|    ep_rew_mean          | 3.45         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 61           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031172214 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.55        |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0093      |\n",
      "|    value_loss           | 66.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 496          |\n",
      "|    ep_rew_mean          | 6.67         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032741386 |\n",
      "|    clip_fraction        | 0.0282       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.469       |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00825     |\n",
      "|    value_loss           | 47.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 502         |\n",
      "|    ep_rew_mean          | 1.56        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 465         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004069153 |\n",
      "|    clip_fraction        | 0.0375      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.378      |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 505          |\n",
      "|    ep_rew_mean          | -1.47        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010091749 |\n",
      "|    clip_fraction        | 0.00688      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.361       |\n",
      "|    explained_variance   | -0.208       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    value_loss           | 42.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 511         |\n",
      "|    ep_rew_mean          | -4.17       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 465         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002155539 |\n",
      "|    clip_fraction        | 0.0137      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.491      |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.66        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0072     |\n",
      "|    value_loss           | 49.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 505          |\n",
      "|    ep_rew_mean          | -6.58        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 83           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025830625 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.448       |\n",
      "|    explained_variance   | 0.782        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 31.7         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00835     |\n",
      "|    value_loss           | 39.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 508          |\n",
      "|    ep_rew_mean          | -1.25        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014860097 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.413       |\n",
      "|    explained_variance   | 0.443        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.2          |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    value_loss           | 41.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 507          |\n",
      "|    ep_rew_mean          | 1.19         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032930044 |\n",
      "|    clip_fraction        | 0.0259       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.464       |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.61         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00967     |\n",
      "|    value_loss           | 30.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 505          |\n",
      "|    ep_rew_mean          | -2.25        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 96           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025454825 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.445       |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00745     |\n",
      "|    value_loss           | 35.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | -1.06        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 101          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020986914 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.433       |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.2         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    value_loss           | 36.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 499         |\n",
      "|    ep_rew_mean          | 1.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 464         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003125981 |\n",
      "|    clip_fraction        | 0.0302      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.456      |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | -1           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 464          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 110          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031714588 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.402       |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.91         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00786     |\n",
      "|    value_loss           | 27.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 493        |\n",
      "|    ep_rew_mean          | 1          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 464        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 114        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00222533 |\n",
      "|    clip_fraction        | 0.0166     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.432     |\n",
      "|    explained_variance   | 0.682      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 12.6       |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.00538   |\n",
      "|    value_loss           | 52.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 486          |\n",
      "|    ep_rew_mean          | -1           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 464          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025528506 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.448       |\n",
      "|    explained_variance   | 0.803        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0082      |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 494          |\n",
      "|    ep_rew_mean          | -1           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 464          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023777415 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.383       |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.09         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    value_loss           | 23.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 501          |\n",
      "|    ep_rew_mean          | 1            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 464          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 127          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022687465 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.339       |\n",
      "|    explained_variance   | 0.894        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.6          |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00558     |\n",
      "|    value_loss           | 20.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 493         |\n",
      "|    ep_rew_mean          | 1           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 464         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002053192 |\n",
      "|    clip_fraction        | 0.0151      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.447      |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.05        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    value_loss           | 47.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 491          |\n",
      "|    ep_rew_mean          | -1           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 464          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030016727 |\n",
      "|    clip_fraction        | 0.0267       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.436       |\n",
      "|    explained_variance   | 0.909        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00673     |\n",
      "|    value_loss           | 19.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 481          |\n",
      "|    ep_rew_mean          | 1            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 464          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 140          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016866226 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.382       |\n",
      "|    explained_variance   | 0.415        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 26.9         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    value_loss           | 35.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 476         |\n",
      "|    ep_rew_mean          | 3           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 464         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003105134 |\n",
      "|    clip_fraction        | 0.0361      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.444      |\n",
      "|    explained_variance   | 0.818       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.26        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 477         |\n",
      "|    ep_rew_mean          | 4           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 465         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002122568 |\n",
      "|    clip_fraction        | 0.0115      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.484      |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m MaskablePPO(MaskableActorCriticPolicy, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1_000_000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/catanatron/lib/python3.11/site-packages/sb3_contrib/ppo_mask/ppo_mask.py:454\u001b[0m, in \u001b[0;36mMaskablePPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, use_masking, progress_bar)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 454\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_masking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/catanatron/lib/python3.11/site-packages/sb3_contrib/ppo_mask/ppo_mask.py:230\u001b[0m, in \u001b[0;36mMaskablePPO.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps, use_masking)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_masking:\n\u001b[1;32m    228\u001b[0m         action_masks \u001b[38;5;241m=\u001b[39m get_action_masks(env)\n\u001b[0;32m--> 230\u001b[0m     actions, values, log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_masks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    233\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(actions)\n",
      "File \u001b[0;32m~/anaconda3/envs/catanatron/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/catanatron/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/catanatron/lib/python3.11/site-packages/sb3_contrib/common/maskable/policies.py:128\u001b[0m, in \u001b[0;36mMaskableActorCriticPolicy.forward\u001b[0;34m(self, obs, deterministic, action_masks)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03mForward pass in all the networks (actor and critic)\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m:return: action, value and log probability of the action\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Preprocess the observation if needed\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor:\n\u001b[1;32m    130\u001b[0m     latent_pi, latent_vf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_extractor(features)\n",
      "File \u001b[0;32m~/anaconda3/envs/catanatron/lib/python3.11/site-packages/sb3_contrib/common/maskable/policies.py:156\u001b[0m, in \u001b[0;36mMaskableActorCriticPolicy.extract_features\u001b[0;34m(self, obs, features_extractor)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03mPreprocess the observation if needed and extract features.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m    features for the actor and the features for the critic.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures_extractor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures_extractor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m features_extractor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/catanatron/lib/python3.11/site-packages/stable_baselines3/common/policies.py:130\u001b[0m, in \u001b[0;36mBaseModel.extract_features\u001b[0;34m(self, obs, features_extractor)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs: PyTorchObs, features_extractor: BaseFeaturesExtractor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    Preprocess the observation if needed and extract features.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    :return: The extracted features\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     preprocessed_obs \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m features_extractor(preprocessed_obs)\n",
      "File \u001b[0;32m~/anaconda3/envs/catanatron/lib/python3.11/site-packages/stable_baselines3/common/preprocessing.py:92\u001b[0m, in \u001b[0;36mpreprocess_obs\u001b[0;34m(obs, observation_space, normalize_images)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 observation \u001b[38;5;241m=\u001b[39m transpose_obs\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m observation\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_obs\u001b[39m(\n\u001b[1;32m     93\u001b[0m     obs: Union[th\u001b[38;5;241m.\u001b[39mTensor, Dict[\u001b[38;5;28mstr\u001b[39m, th\u001b[38;5;241m.\u001b[39mTensor]],\n\u001b[1;32m     94\u001b[0m     observation_space: spaces\u001b[38;5;241m.\u001b[39mSpace,\n\u001b[1;32m     95\u001b[0m     normalize_images: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     96\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[th\u001b[38;5;241m.\u001b[39mTensor, Dict[\u001b[38;5;28mstr\u001b[39m, th\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    Preprocess observation to be to a neural network.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    For images, it normalizes the values by dividing them by 255 (to have values in [0, 1])\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :return:\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation_space, spaces\u001b[38;5;241m.\u001b[39mDict):\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;66;03m# Do not modify by reference the original observation\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "\n",
    "def mask_fn(env) -> np.ndarray:\n",
    "    valid_actions = env.get_valid_actions()\n",
    "    mask = np.zeros(env.action_space.n, dtype=np.float32)\n",
    "    mask[valid_actions] = 1\n",
    "\n",
    "    return np.array([bool(i) for i in mask])\n",
    "\n",
    "\n",
    "# Init Environment and Model\n",
    "env = gym.make(\"catanatron_gym:catanatron-v1\")\n",
    "env = ActionMasker(env, mask_fn)  # Wrap to enable masking\n",
    "model = MaskablePPO(MaskableActorCriticPolicy, env, verbose=1)\n",
    "\n",
    "# Train\n",
    "model.learn(total_timesteps=1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catanatron import Color\n",
    "from catanatron.players.weighted_random import WeightedRandomPlayer\n",
    "from catanatron.players.search import VictoryPointPlayer\n",
    "from catanatron_gym.envs.catanatron_env import from_action_space\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "3\n",
      "[blue]Player:BLUE[/blue]\n",
      "DevCardRandomPlayer:BLUE\n",
      "Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=10)\n",
      "Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=10)\n",
      "3\n",
      "[blue]Player:BLUE[/blue]\n",
      "DevCardRandomPlayer:BLUE\n",
      "Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=34)\n",
      "Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=34)\n",
      "2\n",
      "[blue]Player:BLUE[/blue]\n",
      "LongestRoadRandomPlayer:BLUE\n",
      "Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=32)\n",
      "Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=32)\n",
      "1\n",
      "[blue]Player:BLUE[/blue]\n",
      "SettlementRandomPlayer:BLUE\n",
      "Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=9)\n",
      "Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=9)\n",
      "4\n",
      "[blue]Player:BLUE[/blue]\n",
      "DoNothingRandomPlayer:BLUE\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Cannot choose from an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1_000_000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/catanatron/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/catanatron/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:300\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 300\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/catanatron/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:195\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[1;32m    193\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[0;32m--> 195\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/catanatron/lib/python3.11/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/catanatron/lib/python3.11/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m~/anaconda3/envs/catanatron/lib/python3.11/site-packages/stable_baselines3/common/monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[0;32m~/anaconda3/envs/catanatron/lib/python3.11/site-packages/gymnasium/wrappers/order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/catanatron/lib/python3.11/site-packages/gymnasium/wrappers/env_checker.py:51\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Masters/catanatron/catanatron_gym/catanatron_gym/envs/catanatron_switch_env.py:256\u001b[0m, in \u001b[0;36mCatanatronSwitchEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    254\u001b[0m valid_catan_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mplayable_actions\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m#get chosen action from chosen policy given the valid actions\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m policy_action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapped_policies\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_policy_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchosen_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchosen_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_actions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalid_catan_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28mprint\u001b[39m(policy_action)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Masters/catanatron/catanatron_gym/catanatron_gym/envs/catanatron_switch_env.py:170\u001b[0m, in \u001b[0;36mPolicyWrapper.get_policy_action\u001b[0;34m(self, chosen_policy, valid_actions)\u001b[0m\n\u001b[1;32m    168\u001b[0m policy:Player \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplay_style_list[chosen_policy]\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28mprint\u001b[39m(policy)\n\u001b[0;32m--> 170\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecide\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayable_actions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28mprint\u001b[39m(action)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action\n",
      "File \u001b[0;32m~/Masters/catanatron/catanatron_core/catanatron/players/weighted_random.py:183\u001b[0m, in \u001b[0;36mDoNothingRandomPlayer.decide\u001b[0;34m(self, game, playable_actions)\u001b[0m\n\u001b[1;32m    180\u001b[0m     weight \u001b[38;5;241m=\u001b[39m WEIGHTS_FOR_DO_NOTHING_PLAYER\u001b[38;5;241m.\u001b[39mget(action\u001b[38;5;241m.\u001b[39maction_type, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    181\u001b[0m     bloated_actions\u001b[38;5;241m.\u001b[39mextend([action] \u001b[38;5;241m*\u001b[39m weight)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbloated_actions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/catanatron/lib/python3.11/random.py:373\u001b[0m, in \u001b[0;36mRandom.choice\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# As an accommodation for NumPy, we don't use \"if not seq\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# because bool(numpy.array()) raises a ValueError.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(seq):\n\u001b[0;32m--> 373\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot choose from an empty sequence\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m seq[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow(\u001b[38;5;28mlen\u001b[39m(seq))]\n",
      "\u001b[0;31mIndexError\u001b[0m: Cannot choose from an empty sequence"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def mask_fn(env) -> np.ndarray:\n",
    "    valid_actions = env.get_valid_actions()\n",
    "    mask = np.zeros(env.action_space.n, dtype=np.float32)\n",
    "    mask[valid_actions] = 1\n",
    "\n",
    "    return np.array([bool(i) for i in mask])\n",
    "\n",
    "\n",
    "# Init Environment and Model\n",
    "env = gym.make(\"catanatron_gym:catanatron-switch-v1\")\n",
    "# env = ActionMasker(env, mask_fn)  # Wrap to enable masking\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Train\n",
    "model.learn(total_timesteps=1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catanatron import Color,RandomPlayer\n",
    "from catanatron.players.weighted_random import WeightedRandomPlayer, DevCardRandomPlayer, DoNothingRandomPlayer\n",
    "from catanatron.players.weighted_random import WeightedRandomPlayer\n",
    "\n",
    "from catanatron.players.search import VictoryPointPlayer\n",
    "from catanatron_gym.envs.catanatron_env import from_action_space\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from catanatron_gym.features import create_sample_vector, get_feature_ordering,create_sample\n",
    "from catanatron_gym.envs.catanatron_env import from_action_space\n",
    "# FEATURES = get_feature_ordering\n",
    "from pprint import pprint\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_action_space': None,\n",
      " '_cached_spec': None,\n",
      " '_disable_render_order_enforcing': False,\n",
      " '_has_reset': True,\n",
      " '_metadata': None,\n",
      " '_observation_space': None,\n",
      " '_reward_range': None,\n",
      " '_saved_kwargs': {'disable_render_order_enforcing': False},\n",
      " 'env': <PassiveEnvChecker<CatanatronEnv<catanatron-v1>>>}\n",
      "bloadt actions [Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=0), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=1), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=2), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=3), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=4), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=5), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=6), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=7), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=8), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=9), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=10), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=11), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=12), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=13), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=14), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=15), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=16), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=17), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=18), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=19), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=20), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=21), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=22), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=23), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=24), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=25), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=26), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=27), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=28), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=29), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=30), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=31), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=32), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=33), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=34), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=35), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=36), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=37), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=38), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=39), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=40), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=41), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=42), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=43), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=44), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=45), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=46), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=47), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=48), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=49), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=50), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=51), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=52), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=53)]\n",
      "54\n",
      "Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/catanatron/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.game to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.game` for environment variables or `env.get_wrapper_attr('game')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid_actions': [289]}\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"catanatron_gym:catanatron-v1\")\n",
    "observation, info = env.reset()\n",
    "FEATURES = get_feature_ordering(2)\n",
    "pprint(vars(env))\n",
    "# print(observation)\n",
    "# agent = DevCardRandomPlayer(Color.BLUE)\n",
    "# agent = VictoryPointPlayer(Color.BLUE)\n",
    "# agent = RandomPlayer(Color.BLUE)\n",
    "# env.p0 = WeightedRandomPlayer(Color.BLUE)\n",
    "\n",
    "env.p0 = agent\n",
    "# print((create_sample_vector(game =env.game,p0_color=env.p0.color)))\n",
    "# print(len(env.game.state.playable_actions))\n",
    "# print(env.game.state.playable_actions)\n",
    "# print(len(env.unwrapped.get_valid_actions()))\n",
    "# print(env.unwrapped.get_valid_actions())\n",
    "\n",
    "# print(env.action_space)\n",
    "print(agent.decide(game = env.game, playable_actions=env.unwrapped.game.state.playable_actions))\n",
    "# print(observation)\n",
    "for _ in range(1000):\n",
    "    # your agent here (this takes random actions)\n",
    "    # print(len(env.unwrapped.get_valid_actions()))\n",
    "    # print(env.game.state.playable_actions)\n",
    "    action = random.choice(env.unwrapped.get_valid_actions())\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    if done:\n",
    "        # pprint(vars(env))\n",
    "        # print(env.game.state)\n",
    "        # p\n",
    "        observation, info = env.reset()\n",
    "print(info)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DoNothingRandomPlayer:BLUE\n",
      "playable actions\n",
      " [Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=0), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=1), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=2), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=3), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=4), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=5), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=6), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=7), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=8), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=9), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=11), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=12), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=13), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=14), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=15), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=16), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=17), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=18), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=19), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=20), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=21), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=22), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=23), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=24), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=25), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=26), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=27), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=31), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=32), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=33), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=34), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=35), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=36), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=37), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=38), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=39), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=40), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=41), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=42), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=43), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=44), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=45), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=46), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=47), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=48), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=49), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=50), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=51), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=52), Action(color=<Color.BLUE: 'BLUE'>, action_type=<ActionType.BUILD_SETTLEMENT: 'BUILD_SETTLEMENT'>, value=53)]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Cannot choose from an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# print(action)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# print(from_action_space(action, env.unwrapped.game.state.playable_actions))\u001b[39;00m\n\u001b[1;32m     18\u001b[0m game \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mgame\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munwrapped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecide\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgame\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mplayable_actions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munwrapped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplayable_actions\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print(action)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m~/Masters/catanatron/catanatron_core/catanatron/players/weighted_random.py:197\u001b[0m, in \u001b[0;36mDoNothingRandomPlayer.decide\u001b[0;34m(self, game, playable_actions)\u001b[0m\n\u001b[1;32m    194\u001b[0m     weight \u001b[38;5;241m=\u001b[39m WEIGHTS_FOR_DO_NOTHING_PLAYER\u001b[38;5;241m.\u001b[39mget(action\u001b[38;5;241m.\u001b[39maction_type, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    195\u001b[0m     bloated_actions\u001b[38;5;241m.\u001b[39mextend([action] \u001b[38;5;241m*\u001b[39m weight)\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbloated_actions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/catanatron/lib/python3.11/random.py:373\u001b[0m, in \u001b[0;36mRandom.choice\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# As an accommodation for NumPy, we don't use \"if not seq\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# because bool(numpy.array()) raises a ValueError.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(seq):\n\u001b[0;32m--> 373\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot choose from an empty sequence\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m seq[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow(\u001b[38;5;28mlen\u001b[39m(seq))]\n",
      "\u001b[0;31mIndexError\u001b[0m: Cannot choose from an empty sequence"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"catanatron_gym:catanatron-v1\")\n",
    "observation, info = env.reset()\n",
    "# pprint(vars(env.unwrapped))\n",
    "# print(observation)\n",
    "# env.unwrapped.p0 = DoNothingRandomPlayer(color=Color.BLUE)\n",
    "# env.unwrapped.p0 = DevCardRandomPlayer(color=Color.BLUE)\n",
    "# env.unwrapped.p0 = RandomPlayer(color=Color.BLUE)\n",
    "# pprint(vars(env.unwrapped))\n",
    "pprint(env.unwrapped.p0)\n",
    "for _ in range(1000):\n",
    "    # your agent here (this takes random actions)\n",
    "    action = random.choice(env.unwrapped.get_valid_actions())\n",
    "    # print(env.unwrapped.get_valid_actions())\n",
    "    print(\"playable actions\\n\",env.unwrapped.game.state.playable_actions)\n",
    "    # print(action)\n",
    "    \n",
    "    # print(from_action_space(action, env.unwrapped.game.state.playable_actions))\n",
    "    game = env.game\n",
    "    print(\"agent\",env.unwrapped.p0.decide(game = game ,playable_actions=env.unwrapped.game.state.playable_actions))\n",
    "    # print(action)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    if done:\n",
    "        # pprint(vars(env))\n",
    "        # print(env.game.state)\n",
    "        observation, info = env.reset()\n",
    "print(info)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catanatron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
